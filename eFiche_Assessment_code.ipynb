{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35d23810-146a-40f2-ba42-b46171281adf",
   "metadata": {},
   "source": [
    "                   Marie Diane  Iradukunda\n",
    "                   Efiche assessigment codes part "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e139f223-f9b0-4f22-a96d-f9028f76bb3b",
   "metadata": {},
   "source": [
    "## **Connect to a PostgreSQL Database**\n",
    "\n",
    "\n",
    "This code attempts to connect to a PostgreSQL database.  \n",
    "If the connection is successful, it prints a success message.  \n",
    "If the connection fails, it displays the error message.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "caf57e8b-664d-4b3d-845f-db888f60ef5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected successfully!\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=\"Efiche_assessment1\",\n",
    "        user=\"postgres\",\n",
    "        password=\"didi20189@\",\n",
    "        host=\"localhost\",\n",
    "        port=\"5432\"\n",
    "    )\n",
    "    print(\"Connected successfully!\")\n",
    "    conn.close()\n",
    "except Exception as e:\n",
    "    print(\" Connection failed:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62d0e24-1433-48f7-86b4-70d469d74207",
   "metadata": {},
   "source": [
    "install the faker module "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e972616a-9ea5-41b7-8ddd-be681ee9d416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faker in c:\\users\\m.diane\\anaconda3\\lib\\site-packages (38.0.0)\n",
      "Requirement already satisfied: tzdata in c:\\users\\m.diane\\anaconda3\\lib\\site-packages (from faker) (2023.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install faker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b5a969-8298-4a6b-8de6-5eaf57822aac",
   "metadata": {},
   "source": [
    "**This code generates 5000 synthetic patient records using the Faker library.**  \n",
    "**It connects to a PostgreSQL database and inserts each fake patient into the `patients` table.**  \n",
    "If a patient ID already exists, the record is skipped to avoid conflicts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e6a42fd2-6608-4104-8ddf-35e8e536ddde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 5000 synthetic patients...\n",
      "5000 synthetic patients inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import random\n",
    "from faker import Faker\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"Efiche_assessment1\",\n",
    "    user=\"postgres\",\n",
    "    password=\"didi20189@\",\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "print(\"Generating 5000 synthetic patients...\")\n",
    "\n",
    "for _ in range(5000):\n",
    "    patient_id = fake.uuid4().replace(\"-\", \"\")[:12]\n",
    "    age = random.randint(1, 95)\n",
    "    sex = random.choice(['M', 'F'])\n",
    "    location = f\"{fake.city()}, {fake.state_abbr()}\"\n",
    "\n",
    "    cur.execute(\"\"\"\n",
    "        INSERT INTO patients (patient_id, age, sex, location)\n",
    "        VALUES (%s, %s, %s, %s)\n",
    "        ON CONFLICT (patient_id) DO NOTHING\n",
    "    \"\"\", (patient_id, age, sex, location))\n",
    "\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()\n",
    "print(\"5000 synthetic patients inserted successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7459ee5f-afd1-42db-be9c-bf8b4abdd8d5",
   "metadata": {},
   "source": [
    "**This script builds an automated data ingestion pipeline for the PadChest dataset.**  \n",
    "**It reads the CSV file in chunks, cleans the data, and inserts encounters, reports, procedures, and diagnoses into the PostgreSQL database.**  \n",
    "It also tracks progress using a state file so the pipeline can pause, restart, and continue until all 10,000 rows are processed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "82ee44c9-2443-4487-af88-652a905c4e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eFiche PadChest Ingestion Pipeline STARTED\n",
      "\n",
      " COMPLETED — 10,000+ rows ingested successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "eFiche Assessment – Part 2: Continuous PadChest Ingestion Pipeline\n",
    "- Incremental (stateful) ingestion of first 10,000+ rows\n",
    "- Handles duplicates gracefully\n",
    "- Random patient matching (as per requirement #4)\n",
    "- Works with official Part 1 schema (TEXT IDs)\n",
    "\"\"\"\n",
    "\n",
    "import os, json, time, random, pandas as pd, psycopg2\n",
    "from psycopg2.extras import execute_values\n",
    "\n",
    "DB_CONFIG = {\"dbname\": \"Efiche_assessment1\", \"user\": \"postgres\", \"password\": \"didi20189@\", \"host\": \"localhost\", \"port\": \"5432\"}\n",
    "CSV_PATH = \"C:/Users/M.Diane/Desktop/padchest_metadata.csv\"  \n",
    "STATE_FILE = \"pipeline_state.json\"\n",
    "CHUNK_SIZE = 5000\n",
    "SLEEP_SECONDS = 60\n",
    "TARGET_ROWS = 10000\n",
    "\n",
    "def load_state():\n",
    "    return json.load(open(STATE_FILE)).get(\"processed_rows\", 0) if os.path.exists(STATE_FILE) else 0\n",
    "\n",
    "def save_state(rows):\n",
    "    json.dump({\"processed_rows\": rows}, open(STATE_FILE, \"w\"))\n",
    "\n",
    "def read_new_rows(start_row):\n",
    "    if not os.path.exists(CSV_PATH):\n",
    "        print(f\"ERROR: CSV file not found at: {CSV_PATH}\")\n",
    "        return pd.DataFrame()\n",
    "    print(f\"Opening CSV: {CSV_PATH}\")\n",
    "    try:\n",
    "        df = pd.read_csv(CSV_PATH, skiprows=range(1, start_row + 1), nrows=CHUNK_SIZE, dtype=str, on_bad_lines=\"skip\", encoding=\"utf-8\")\n",
    "        print(f\"Read {len(df)} new rows (from row {start_row})\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"CSV read error: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def ingest_chunk(df):\n",
    "    if df.empty: return 0\n",
    "    conn = psycopg2.connect(**DB_CONFIG); cur = conn.cursor()\n",
    "    cur.execute(\"SELECT patient_id FROM patients\"); patients = [r[0] for r in cur.fetchall()]\n",
    "    if not patients:\n",
    "        print(\"No patients in DB — run synthetic data first!\"); conn.close(); return 0\n",
    "\n",
    "    # Encounters + Reports\n",
    "    data = [(str(r[\"StudyID\"]), random.choice(patients), \"1\",\n",
    "             pd.to_datetime(r[\"StudyDate_DICOM\"], format=\"%Y%m%d\", errors=\"coerce\").date(),\n",
    "             str(r[\"StudyID\"]), str(r[\"StudyID\"]), r.get(\"Report\") or None, \"es\") for _, r in df.iterrows()]\n",
    "\n",
    "    inserted_enc = updated_rep = 0\n",
    "    sql = \"\"\"\n",
    "        INSERT INTO encounters VALUES (%s,%s,%s,%s) ON CONFLICT DO NOTHING;\n",
    "        INSERT INTO reports VALUES (%s,%s,%s,%s)\n",
    "        ON CONFLICT (report_id) DO UPDATE SET text = EXCLUDED.text\n",
    "        RETURNING (xmax = 0);\n",
    "    \"\"\"\n",
    "    for rec in data:\n",
    "        cur.execute(sql, rec)\n",
    "        if cur.rowcount: inserted_enc += 1\n",
    "        if cur.fetchone() and not cur.fetchone()[0]: updated_rep += 1\n",
    "\n",
    "    # Procedures\n",
    "    proc = [(str(r[\"ImageID\"]), str(r[\"StudyID\"]), \"Chest X-Ray\", r.get(\"Modality_DICOM\"), r.get(\"Projection\")) for _, r in df.iterrows()]\n",
    "    inserted_proc = 0\n",
    "    if proc:\n",
    "        execute_values(cur, \"INSERT INTO procedures VALUES %s ON CONFLICT DO NOTHING RETURNING procedure_id\", proc)\n",
    "        inserted_proc = cur.rowcount\n",
    "\n",
    "    # Diagnoses + Junction\n",
    "    diag_codes = set(); junc = []\n",
    "    if \"Labels\" in df.columns:\n",
    "        for _, r in df.iterrows():\n",
    "            labels = r[\"Labels\"]; sid = str(r[\"StudyID\"])\n",
    "            if pd.isna(labels) or str(labels).strip() in (\"[]\", \"nan\", \"\"): continue\n",
    "            codes = [c.strip().strip(\"'\") for c in str(labels).strip(\"[]\").split(\",\") if c.strip()]\n",
    "            for c in codes:\n",
    "                diag_codes.add(c); junc.append((sid, c))\n",
    "    inserted_diag = 0\n",
    "    if diag_codes:\n",
    "        execute_values(cur, \"INSERT INTO diagnoses (code,description) VALUES %s ON CONFLICT DO NOTHING RETURNING code\", [(c,c) for c in diag_codes])\n",
    "        inserted_diag = cur.rowcount\n",
    "    inserted_junc = 0\n",
    "    for enc_id, code in junc:\n",
    "        cur.execute(\"INSERT INTO encounter_diagnoses (encounter_id,diagnosis_id) SELECT %s,diagnosis_id FROM diagnoses WHERE code=%s ON CONFLICT DO NOTHING RETURNING encounter_id\", (enc_id, code))\n",
    "        if cur.rowcount: inserted_junc += 1\n",
    "\n",
    "    conn.commit(); cur.close(); conn.close()\n",
    "\n",
    "    print(f\"Inserted/updated ~{len(df)}+ records (encounters, procedures, diagnoses)\")\n",
    "    print(f\"   -> Encounters: {inserted_enc} inserted, {len(data)-inserted_enc} duplicates skipped\")\n",
    "    print(f\"   -> Reports: {updated_rep} text fields updated\")\n",
    "    print(f\"   -> Procedures: {inserted_proc} inserted, {len(proc)-inserted_proc} duplicates skipped\")\n",
    "    print(f\"   -> Diagnoses: {inserted_diag} new codes added\")\n",
    "    print(f\"   -> Encounter-Diagnoses: {inserted_junc} links created\")\n",
    "    return len(df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"eFiche PadChest Ingestion Pipeline STARTED\")\n",
    "    processed = load_state()\n",
    "    while processed < TARGET_ROWS:\n",
    "        df = read_new_rows(processed)\n",
    "        if df.empty:\n",
    "            print(\"No more data in CSV. Pipeline complete.\")\n",
    "            break\n",
    "        processed += ingest_chunk(df)\n",
    "        save_state(processed)\n",
    "        print(f\"Total processed: {processed}/{TARGET_ROWS} rows\")\n",
    "        if processed < TARGET_ROWS:\n",
    "            print(f\"Sleeping {SLEEP_SECONDS} seconds...\\n\")\n",
    "            time.sleep(SLEEP_SECONDS)\n",
    "    print(\"\\n COMPLETED — 10,000+ rows ingested successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54bf207-616d-441a-8bdc-5de87057ecdc",
   "metadata": {},
   "source": [
    "Intrepretation :\n",
    "The script connects to PostgreSQL and fills the date and dimension tables (patients, procedures, diagnoses) from the source system.\n",
    "\n",
    "It then builds the fact_encounter table by joining encounters with their related patient, procedure, diagnosis, date, and report.\n",
    "\n",
    "Finally, it commits all inserts and fully populates the data warehouse (DWH)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fc71bede-0f33-4976-89b3-576fa8c3f9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating dim_date (2010–2025)...\n",
      "ETL: Loading dimensions and fact table...\n",
      "PART 3 ETL COMPLETE — DWH FULLY POPULATED\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_values\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"Efiche_assessment1\",\n",
    "    user=\"postgres\",\n",
    "    password=\"didi20189@\",\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "print(\"Populating dim_date (2010–2025)...\")\n",
    "cur.execute(\"\"\"\n",
    "    INSERT INTO dwh.dim_date (full_date, year, month, day, quarter, month_name, day_of_week, is_weekend)\n",
    "    SELECT d::date,\n",
    "           EXTRACT(YEAR FROM d)::int,\n",
    "           EXTRACT(MONTH FROM d)::int,\n",
    "           EXTRACT(DAY FROM d)::int,\n",
    "           EXTRACT(QUARTER FROM d)::int,\n",
    "           TO_CHAR(d, 'Month'),\n",
    "           TO_CHAR(d, 'Day'),\n",
    "           CASE WHEN EXTRACT(DOW FROM d) IN (0,6) THEN TRUE ELSE FALSE END\n",
    "    FROM generate_series('2010-01-01'::date, '2025-12-31'::date, '1 day'::interval) d\n",
    "    ON CONFLICT (full_date) DO NOTHING;\n",
    "\"\"\")\n",
    "\n",
    "print(\"ETL: Loading dimensions and fact table...\")\n",
    "\n",
    "# 1. dim_patient\n",
    "cur.execute(\"\"\"\n",
    "    INSERT INTO dwh.dim_patient (patient_id, age, sex, location)\n",
    "    SELECT patient_id, age, sex, location FROM patients\n",
    "    ON CONFLICT (patient_id) DO NOTHING;\n",
    "\"\"\")\n",
    "\n",
    "# 2. dim_procedure\n",
    "cur.execute(\"\"\"\n",
    "    INSERT INTO dwh.dim_procedure (procedure_id, procedure_name, modality, projection)\n",
    "    SELECT procedure_id, procedure_name, modality, projection FROM procedures\n",
    "    ON CONFLICT (procedure_id) DO NOTHING;\n",
    "\"\"\")\n",
    "\n",
    "# 3. dim_diagnosis\n",
    "cur.execute(\"\"\"\n",
    "    INSERT INTO dwh.dim_diagnosis (diagnosis_id, code, description)\n",
    "    SELECT diagnosis_id, code, description FROM diagnoses\n",
    "    ON CONFLICT (diagnosis_id) DO NOTHING;\n",
    "\"\"\")\n",
    "\n",
    "# 4. fact_encounter (NOW WORKS!)\n",
    "cur.execute(\"\"\"\n",
    "    INSERT INTO dwh.fact_encounter (\n",
    "        encounter_id, patient_key, procedure_key, diagnosis_key, date_key, report_text, report_language\n",
    "    )\n",
    "    SELECT \n",
    "        e.encounter_id,\n",
    "        dp.patient_key,\n",
    "        dpr.procedure_key,\n",
    "        dd.diagnosis_key,\n",
    "        ddate.date_key,\n",
    "        r.text,\n",
    "        r.language\n",
    "    FROM encounters e\n",
    "    JOIN patients p ON e.patient_id = p.patient_id\n",
    "    JOIN dwh.dim_patient dp ON p.patient_id = dp.patient_id\n",
    "    JOIN procedures pr ON e.encounter_id = pr.encounter_id\n",
    "    JOIN dwh.dim_procedure dpr ON pr.procedure_id = dpr.procedure_id\n",
    "    LEFT JOIN encounter_diagnoses ed ON e.encounter_id = ed.encounter_id\n",
    "    LEFT JOIN dwh.dim_diagnosis dd ON ed.diagnosis_id = dd.diagnosis_id\n",
    "    JOIN dwh.dim_date ddate ON e.encounter_date = ddate.full_date\n",
    "    LEFT JOIN reports r ON e.encounter_id = r.encounter_id\n",
    "    ON CONFLICT (encounter_id) DO NOTHING;\n",
    "\"\"\")\n",
    "\n",
    "conn.commit()\n",
    "print(\"PART 3 ETL COMPLETE — DWH FULLY POPULATED\")\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8ca231-16ac-4b2c-a845-01313470210c",
   "metadata": {},
   "source": [
    "## DASHBOARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e583797a-44a1-4755-8001-a0c627f148ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connected successfully.\n",
      "Loading data from database...\n",
      "Data loaded successfully.\n",
      "3 HTML files saved in /submission folder!\n",
      "clinical_dashboard_full.html generated with auto-download!\n",
      "   → Open in browser: auto-downloads + has download button\n",
      "\n",
      "============================================================\n",
      "BONUS DASHBOARD COMPLETE\n",
      "============================================================\n",
      "1. Live Dashboard → http://127.0.0.1:8050\n",
      "2. Static HTML → clinical_dashboard_full.html (auto-downloads on open)\n",
      "3. Submission → /submission/*.html\n",
      "4. Download buttons in both static & live versions!\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x235b8873cb0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from dash import Dash, html, dcc\n",
    "import dash_bootstrap_components as dbc\n",
    "import os\n",
    "import base64\n",
    "\n",
    "# ==============================\n",
    "# 1. Database Connection\n",
    "# ==============================\n",
    "def get_connection():\n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            dbname=\"Efiche_assessment1\",\n",
    "            user=\"postgres\",\n",
    "            password=\"didi20189@\",\n",
    "            host=\"localhost\",\n",
    "            port=\"5432\"\n",
    "        )\n",
    "        print(\"Database connected successfully.\")\n",
    "        return conn\n",
    "    except Exception as e:\n",
    "        print(f\"Database connection failed: {e}\")\n",
    "        exit(1)\n",
    "\n",
    "conn = get_connection()\n",
    "\n",
    "# ==============================\n",
    "# 2. Load Data\n",
    "# ==============================\n",
    "try:\n",
    "    print(\"Loading data from database...\")\n",
    "    # 1. Encounters per Month\n",
    "    df_monthly = pd.read_sql(\"\"\"\n",
    "        SELECT dd.year, dd.month_name, dd.month, COUNT(*) AS encounters\n",
    "        FROM dwh.fact_encounter f\n",
    "        JOIN dwh.dim_date dd ON f.date_key = dd.date_key\n",
    "        GROUP BY dd.year, dd.month_name, dd.month\n",
    "        ORDER BY dd.year, dd.month\n",
    "    \"\"\", conn)\n",
    "\n",
    "    # 2. Top Diagnoses by Age Group\n",
    "    df_diag = pd.read_sql(\"\"\"\n",
    "        WITH age_groups AS (\n",
    "            SELECT patient_key,\n",
    "                   CASE WHEN age < 18 THEN '0-17'\n",
    "                        WHEN age BETWEEN 18 AND 34 THEN '18-34'\n",
    "                        WHEN age BETWEEN 35 AND 54 THEN '35-54'\n",
    "                        ELSE '55+' END AS age_group\n",
    "            FROM dwh.dim_patient WHERE is_current\n",
    "        )\n",
    "        SELECT ag.age_group, ddiag.code, COUNT(*) AS count\n",
    "        FROM dwh.fact_encounter f\n",
    "        JOIN age_groups ag ON f.patient_key = ag.patient_key\n",
    "        JOIN dwh.dim_diagnosis ddiag ON f.diagnosis_key = ddiag.diagnosis_key\n",
    "        GROUP BY ag.age_group, ddiag.code\n",
    "        ORDER BY count DESC LIMIT 15\n",
    "    \"\"\", conn)\n",
    "\n",
    "    # 3. Average Studies per Patient\n",
    "    avg_studies = pd.read_sql(\"\"\"\n",
    "        SELECT ROUND(AVG(study_count)::numeric, 2) AS avg_studies_per_patient\n",
    "        FROM (\n",
    "            SELECT patient_id, COUNT(*) AS study_count\n",
    "            FROM encounters\n",
    "            GROUP BY patient_id\n",
    "        ) t\n",
    "    \"\"\", conn).iloc[0]['avg_studies_per_patient']\n",
    "\n",
    "    # 4. Top Diagnosis Clusters\n",
    "    df_clusters = pd.read_sql(\"\"\"\n",
    "        SELECT word, COUNT(*) AS frequency\n",
    "        FROM (\n",
    "            SELECT unnest(string_to_array(lower(regexp_replace(COALESCE(text, ''), '[^a-záéíóúñ ]', '', 'g')), ' ')) AS word\n",
    "            FROM reports\n",
    "            WHERE text IS NOT NULL AND text <> ''\n",
    "        ) words\n",
    "        WHERE word IN ('pneumonia', 'cardiomegaly', 'edema', 'effusion', 'atelectasis',\n",
    "                       'normal', 'consolidation', 'infiltrates', 'opacity', 'fracture', 'mass', 'nodule')\n",
    "        GROUP BY word\n",
    "        ORDER BY frequency DESC\n",
    "    \"\"\", conn)\n",
    "\n",
    "    print(\"Data loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Query failed: {e}\")\n",
    "    conn.close()\n",
    "    exit(1)\n",
    "finally:\n",
    "    conn.close()\n",
    "\n",
    "# ==============================\n",
    "# 3. Create Figures\n",
    "# ==============================\n",
    "# Fig 1: Encounters per Month\n",
    "fig1 = px.bar(\n",
    "    df_monthly,\n",
    "    x=\"month_name\",\n",
    "    y=\"encounters\",\n",
    "    color=\"year\",\n",
    "    title=\"Number of encounters per month \",\n",
    "    labels={\"encounters\": \"Number of Studies\", \"month_name\": \"Month\"},\n",
    "    height=520,\n",
    "    template=\"simple_white\"\n",
    ")\n",
    "fig1.update_layout(barmode='group', legend_title=\"Year\", title_x=0.5, font=dict(family=\"Arial, sans-serif\"))\n",
    "\n",
    "# Fig 2: Top Diagnoses by Age Group\n",
    "fig2 = px.bar(\n",
    "    df_diag,\n",
    "    x=\"code\",\n",
    "    y=\"count\",\n",
    "    color=\"age_group\",\n",
    "    title=\"Top 15 Diagnoses by Age Group\",\n",
    "    labels={\"count\": \"Diagnosis Count\", \"code\": \"Diagnosis Code\"},\n",
    "    barmode=\"group\",\n",
    "    height=520,\n",
    "    template=\"simple_white\"\n",
    ")\n",
    "fig2.update_layout(xaxis_tickangle=45, legend_title=\"Age Group\", title_x=0.5)\n",
    "\n",
    "# Fig 4: Diagnosis Clusters\n",
    "fig4 = px.bar(\n",
    "    df_clusters,\n",
    "    x=\"word\",\n",
    "    y=\"frequency\",\n",
    "    color=\"frequency\",\n",
    "    title=\"Top Diagnosis Clusters from Report Text\",\n",
    "    labels={\"frequency\": \"Frequency\", \"word\": \"Clinical Term\"},\n",
    "    height=500,\n",
    "    template=\"simple_white\",\n",
    "    color_continuous_scale=\"Viridis\"\n",
    ")\n",
    "fig4.update_layout(xaxis_tickangle=45, title_x=0.5)\n",
    "\n",
    "# ==============================\n",
    "# 4. Save Individual HTML Files\n",
    "# ==============================\n",
    "def save_individual_html():\n",
    "    os.makedirs(\"submission\", exist_ok=True)\n",
    "    fig1.write_html(\"submission/dashboard_encounters_by_month.html\")\n",
    "    fig2.write_html(\"submission/dashboard_diagnoses_by_age.html\")\n",
    "    fig4.write_html(\"submission/dashboard_diagnosis_clusters.html\")\n",
    "    print(\"3 HTML files saved in /submission folder!\")\n",
    "\n",
    "save_individual_html()\n",
    "\n",
    "# ==============================\n",
    "# 5. Generate Full Static HTML + Auto-Download\n",
    "# ==============================\n",
    "def generate_full_html():\n",
    "    html_content = f\"\"\"<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "  <meta charset=\"UTF-8\" />\n",
    "  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"/>\n",
    "  <title>Clinical Analytics Dashboard</title>\n",
    "  <link href=\"https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css\" rel=\"stylesheet\"/>\n",
    "  <script src=\"https://cdn.plot.ly/plotly-2.27.0.min.js\"></script>\n",
    "  <style>\n",
    "    body {{ background: #f8f9fa; font-family: 'Segoe UI', sans-serif; padding: 20px; }}\n",
    "    .kpi-card {{ background: linear-gradient(135deg, #3498db, #2980b9); color: white; border-radius: 15px; box-shadow: 0 8px 20px rgba(0,0,0,0.15); }}\n",
    "    .kpi-value {{ font-size: 3.2rem; font-weight: 800; }}\n",
    "    .chart-box {{ background: white; border-radius: 15px; padding: 20px; margin-bottom: 25px; box-shadow: 0 4px 15px rgba(0,0,0,0.08); }}\n",
    "    .footer {{ margin-top: 50px; color: #6c757d; }}\n",
    "    h1 {{ color: #2c3e50; }}\n",
    "    .download-btn {{ position: fixed; top: 20px; right: 20px; z-index: 1000; }}\n",
    "  </style>\n",
    "</head>\n",
    "<body>\n",
    "  <!-- Download Button -->\n",
    "  <button class=\"btn btn-success download-btn shadow-lg\" onclick=\"downloadDashboard()\">\n",
    "    Download Dashboard (HTML)\n",
    "  </button>\n",
    "\n",
    "  <div class=\"container-fluid\">\n",
    "    <h1 class=\"text-center mb-4 fw-bold\">Clinical Analytics Dashboard</h1>\n",
    "    <!-- KPI -->\n",
    "    <div class=\"row justify-content-center mb-5\">\n",
    "      <div class=\"col-md-4 col-sm-6\">\n",
    "        <div class=\"card kpi-card text-center p-3\">\n",
    "          <div class=\"card-body\">\n",
    "            <div class=\"kpi-value\">{avg_studies}</div>\n",
    "            <p class=\"mb-0 fw-bold\">Average Studies per Patient</p>\n",
    "            <small> </small>\n",
    "          </div>\n",
    "        </div>\n",
    "      </div>\n",
    "    </div>\n",
    "    <!-- Charts -->\n",
    "    <div class=\"row\">\n",
    "      <div class=\"col-lg-6\"><div class=\"chart-box\" id=\"chart1\"></div></div>\n",
    "      <div class=\"col-lg-6\"><div class=\"chart-box\" id=\"chart2\"></div></div>\n",
    "    </div>\n",
    "    <div class=\"row justify-content-center\">\n",
    "      <div class=\"col-lg-8\"><div class=\"chart-box\" id=\"chart4\"></div></div>\n",
    "    </div>\n",
    "    <div class=\"footer text-center\">\n",
    "      <hr><p>Data Source: PadChest </p>\n",
    "    </div>\n",
    "  </div>\n",
    "\n",
    "  <script>\n",
    "    const fig1 = {fig1.to_json()};\n",
    "    const fig2 = {fig2.to_json()};\n",
    "    const fig4 = {fig4.to_json()};\n",
    "    Plotly.newPlot('chart1', fig1.data, fig1.layout, {{responsive: true}});\n",
    "    Plotly.newPlot('chart2', fig2.data, fig2.layout, {{responsive: true}});\n",
    "    Plotly.newPlot('chart4', fig4.data, fig4.layout, {{responsive: true}});\n",
    "\n",
    "    // Auto-download after 1 second (optional — remove if unwanted)\n",
    "    setTimeout(downloadDashboard, 1000);\n",
    "\n",
    "    function downloadDashboard() {{\n",
    "      const content = document.documentElement.outerHTML;\n",
    "      const blob = new Blob([content], {{ type: 'text/html' }});\n",
    "      const url = URL.createObjectURL(blob);\n",
    "      const a = document.createElement('a');\n",
    "      a.href = url;\n",
    "      a.download = 'clinical_dashboard_full.html';\n",
    "      document.body.appendChild(a);\n",
    "      a.click();\n",
    "      document.body.removeChild(a);\n",
    "      URL.revokeObjectURL(url);\n",
    "    }}\n",
    "  </script>\n",
    "</body>\n",
    "</html>\"\"\"\n",
    "\n",
    "    filename = \"clinical_dashboard_full.html\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html_content)\n",
    "    print(f\"{filename} generated with auto-download!\")\n",
    "    print(\"   → Open in browser: auto-downloads + has download button\")\n",
    "\n",
    "generate_full_html()\n",
    "\n",
    "# ==============================\n",
    "# 6. Dash App Setup + Download Button\n",
    "# ==============================\n",
    "app = Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "\n",
    "# Create download link for full HTML\n",
    "def get_dashboard_download_link():\n",
    "    with open(\"clinical_dashboard_full.html\", \"r\", encoding=\"utf-8\") as f:\n",
    "        html_string = f.read()\n",
    "    b64 = base64.b64encode(html_string.encode()).decode()\n",
    "    return html.A(\n",
    "        html.Button(\"Download Full Dashboard (HTML)\", className=\"btn btn-success shadow\"),\n",
    "        href=f\"data:text/html;base64,{b64}\",\n",
    "        download=\"clinical_dashboard_full.html\",\n",
    "        className=\"position-fixed\",\n",
    "        style={\"top\": \"20px\", \"right\": \"20px\", \"zIndex\": 1000}\n",
    "    )\n",
    "\n",
    "kpi_card = dbc.Card(\n",
    "    dbc.CardBody([\n",
    "        html.H3(f\"{avg_studies}\", className=\"text-primary fw-bold mb-1\"),\n",
    "        html.P(\"Average Studies per Patient\", className=\"mb-0\"),\n",
    "        html.Small(\" \", className=\"text-muted\")\n",
    "    ], className=\"text-center p-4 shadow\"),\n",
    "    className=\"border-start border-primary border-5\"\n",
    ")\n",
    "\n",
    "app.layout = dbc.Container([\n",
    "    get_dashboard_download_link(),  # Download button in live app\n",
    "    html.H1(\"Clinical Analytics Dashboard\", className=\"text-center my-4 text-primary fw-bold\"),\n",
    "    dbc.Row(dbc.Col(kpi_card, md=4), className=\"justify-content-center mb-4\"),\n",
    "    dbc.Row([\n",
    "        dbc.Col(dcc.Graph(figure=fig1), lg=6, className=\"mb-4\"),\n",
    "        dbc.Col(dcc.Graph(figure=fig2), lg=6, className=\"mb-4\"),\n",
    "    ]),\n",
    "    dbc.Row([\n",
    "        dbc.Col(dcc.Graph(figure=fig4), lg=8, className=\"mx-auto\")\n",
    "    ]),\n",
    "    html.Hr(),\n",
    "    html.P(\"Data Source: PadChest \", className=\"text-center text-muted small\")\n",
    "], fluid=True, className=\"py-3\")\n",
    "\n",
    "# ==============================\n",
    "# 7. Run Server\n",
    "# ==============================\n",
    "if __name__ == '__main__':\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"BONUS DASHBOARD COMPLETE\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"1. Live Dashboard → http://127.0.0.1:8050\")\n",
    "    print(\"2. Static HTML → clinical_dashboard_full.html (auto-downloads on open)\")\n",
    "    print(\"3. Submission → /submission/*.html\")\n",
    "    print(\"4. Download buttons in both static & live versions!\")\n",
    "    print(\"=\"*60)\n",
    "   \n",
    "    app.run(debug=False, port=8050)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
